{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "201f0e34",
   "metadata": {},
   "source": [
    "#### 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb94765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt  # or\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a7755e",
   "metadata": {},
   "source": [
    "#### 2. Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36616c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('Bank_Personal_Loan_Modelling.xlsx', sheet_name=1)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7733cf08",
   "metadata": {},
   "source": [
    "In pandas, when using df.drop(), the axis parameter specifies whether you intend to drop rows or columns.\n",
    "axis=0 or axis='index':\n",
    "This indicates that the operation should be performed along the rows, meaning you are dropping rows. This is the default behavior if axis is not explicitly specified.\n",
    "axis=1 or axis='columns':\n",
    "This indicates that the operation should be performed along the columns, meaning you are dropping columns.\n",
    "\n",
    "In pandas, setting inplace=True within a method means that the operation will modify the DataFrame or Series object directly, without creating a new object and returning it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4fb02c",
   "metadata": {},
   "source": [
    "#### 3. Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3b341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['ID']\n",
    "df.drop(columns=drop_columns, axis=0, inplace=True)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27856e8",
   "metadata": {},
   "source": [
    "#### 4. Checking if there is any null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44688eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if data is null anywhere in table\n",
    "\n",
    "null_counts = df.isnull().sum()\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13f5e9c",
   "metadata": {},
   "source": [
    "#### 5. Distributing data into features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647bad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_X = df.drop(columns=['Personal Loan'])\n",
    "# features_X.describe()\n",
    "target_Y = df['Personal Loan']\n",
    "# target_Y.describe()\n",
    "\n",
    "features_matrix = features_X.to_numpy()\n",
    "print(features_matrix)\n",
    "\n",
    "print(features_matrix.shape)\n",
    "\n",
    "target_vector = target_Y.to_numpy()\n",
    "\n",
    "print(target_vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9575475",
   "metadata": {},
   "source": [
    "#### 6. Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8026337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler() # Fit scaler to features matrix\n",
    "\n",
    "#scaled features_matrix = scaler.fit_transform(features_matrix)\n",
    "scaled_features_matrix = scaler.fit_transform(features_matrix)\n",
    "print(scaled_features_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f51a096",
   "metadata": {},
   "source": [
    "#### 7. Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530a6da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features_matrix, target_vector, test_size=0.2, random_state=42)\n",
    "# X_train.shape\n",
    "# X_test\n",
    "# y_train\n",
    "# y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42e42db",
   "metadata": {},
   "source": [
    "#### 8. Initializing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbd6324",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(X_train.shape[1],)),  # Input + hidden layer\n",
    "    Dense(8, activation='relu'),                                     # Another hidden layer\n",
    "    Dense(1, activation='sigmoid')                                   # Output layer (binary classification)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c31c627",
   "metadata": {},
   "source": [
    "#### 9. Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544168a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c71003",
   "metadata": {},
   "source": [
    "#### 10. Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7848530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=20,\n",
    "    batch_size=50,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523282ac",
   "metadata": {},
   "source": [
    "#### 11. Plotting the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58826aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss\n",
    "plt.plot(history.history['loss'], label='Training loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "plt.title('Model Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Also for accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "# use pandas to create graphs! df.plot and on backend use matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b55095a",
   "metadata": {},
   "source": [
    "#### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb53bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
